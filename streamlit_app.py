import streamlit as st
import torch
import json
import os
import gdown
import numpy as np
from transformers import AutoTokenizer
from model import JointACDSPCModel
import matplotlib.pyplot as plt
import pandas as pd
import altair as alt

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ARTIFACT_DIR = "/absa_prepared"

# T·∫£i th·∫≥ng file .pt v√†o root app
MODEL_PATH = "joint_acd_spc_model_final.pt"
GDRIVE_FILE_URL = "https://drive.google.com/uc?id=1p99F1BKmL6mEZdPcDFzfQjN4Pv37UF51"  # link tr·ª±c ti·∫øp

print("Model exists?", os.path.exists(MODEL_PATH))

def download_model_from_drive():
    """T·∫£i model t·ª´ Google Drive n·∫øu ch∆∞a c√≥"""
    if not os.path.exists(MODEL_PATH):
        gdown.download(
            url=GDRIVE_FILE_URL,
            output=MODEL_PATH,
            quiet=False,
            fuzzy=True
        )

# ---------- Load artifacts ----------
@st.cache_resource
def load_all():
    # 1Ô∏è‚É£ t·∫£i model .pt (n·∫øu ch∆∞a c√≥)
    download_model_from_drive()

    # 2Ô∏è‚É£ load meta
    with open(f"{ARTIFACT_DIR}/meta.json") as f:
        meta = json.load(f)

    with open(f"{ARTIFACT_DIR}/model_kwargs.json") as f:
        model_kwargs = json.load(f)

    tokenizer = AutoTokenizer.from_pretrained(f"{ARTIFACT_DIR}/tokenizer")

    model = JointACDSPCModel(**model_kwargs)
    model.load_state_dict(
        torch.load(
            MODEL_PATH,
            map_location=DEVICE
        )
    )

    model.to(DEVICE)
    model.eval()

    return model, tokenizer, meta


model, tokenizer, meta = load_all()



categories = meta["categories"]
idx2cat = {int(k): v for k, v in meta["idx2cat"].items()}
MAX_LEN = meta["max_len"]
THRESHOLD = meta["threshold"]
df = None


sentiment_map = {0: "neutral", 1: "positive", 2: "negative"}

# ---------- Prediction ----------
def predict(text, threshold):
    enc = tokenizer(
        text,
        padding="max_length",
        truncation=True,
        max_length=MAX_LEN,
        return_tensors="pt"
    )
    enc = {k: v.to(DEVICE) for k, v in enc.items()}

    with torch.no_grad():
        acd_logits, spc_logits = model(**enc)

    acd_probs = torch.sigmoid(acd_logits)[0].cpu().numpy()
    spc_logits = spc_logits[0].view(len(categories), 3)
    spc_probs = torch.softmax(spc_logits, dim=1).cpu().numpy()
    spc_preds = np.argmax(spc_probs, axis=1)

    results = []
    for i, p in enumerate(acd_probs):
        if p >= threshold:
            results.append({
                "aspect": idx2cat[i],
                "sentiment": sentiment_map[spc_preds[i]],
                "confidence": float(p),
                "sentiment_probs": spc_probs[i]
            })
    return results

# Sidebar ‚Äì control panel
st.set_page_config(page_title="ABSA Demo", layout="centered")
st.markdown(
    """
    <style>
        .block-container {
            padding-top: 2rem;
            padding-bottom: 4rem;
            max-width: 95%;
        }
    </style>
    """,
    unsafe_allow_html=True
)


st.sidebar.title("‚öôÔ∏è Settings")

threshold = st.sidebar.slider(
    "ACD Threshold",
    min_value=0.1,
    max_value=0.9,
    value=THRESHOLD,
    step=0.05
)

show_details = st.sidebar.checkbox("Show detailed scores", value=False)

st.sidebar.markdown("---")
st.sidebar.markdown("**Model:**")
st.sidebar.write(meta["model_name"])
st.sidebar.write(f"Num aspects: {len(categories)}")




# ---------- Streamlit UI ----------
st.set_page_config(page_title="ABSA Demo", layout="centered")

st.title("üîç Aspect-Based Sentiment Analysis")
st.write("Nh·∫≠p ph·∫£n h·ªìi kh√°ch h√†ng ƒë·ªÉ ph√¢n t√≠ch **aspect & sentiment**")

text = st.text_area("‚úçÔ∏è Nh·∫≠p c√¢u:", height=120)

if st.button("üöÄ Ph√¢n t√≠ch"):
    if not text.strip():
        st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung.")
    else:
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            results = predict(text, threshold)

        if len(results) == 0:
            st.info("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán aspect n√†o v∆∞·ª£t ng∆∞·ª°ng.")
        else:
            st.success("‚úÖ K·∫øt qu·∫£ ph√¢n t√≠ch")

            for r in results:
                color = {
                    "positive": "green",
                    "negative": "red",
                    "neutral": "orange"
                }[r["sentiment"]]

                st.markdown(
                    f"""
                    **{r['aspect']}**  
                    <span style="color:{color}; font-weight:bold">
                    {r['sentiment']}
                    </span>  
                    Confidence: `{r['confidence']:.2f}`
                    """,
                    unsafe_allow_html=True
                )

                if show_details:
                    st.write(
                        f"‚Ä¢ Sentiment probs ‚Üí "
                        f"Pos: {r['sentiment_probs'][1]:.2f}, "
                        f"Neu: {r['sentiment_probs'][0]:.2f}, "
                        f"Neg: {r['sentiment_probs'][2]:.2f}"
                    )

                st.markdown("---")

def batch_predict(sentences, threshold):
    rows = []

    for sid, text in enumerate(sentences, 1):
        text = text.strip()
        if not text:
            continue

        preds = predict(text, threshold)

        if len(preds) == 0:
            rows.append({
                "sentence_id": sid,
                "sentence": text,
                "aspect": None,
                "sentiment": None,
                "confidence": None
            })
        else:
            for r in preds:
                rows.append({
                    "sentence_id": sid,
                    "sentence": text,
                    "aspect": r["aspect"],
                    "sentiment": r["sentiment"],
                    "confidence": r["confidence"]
                })

    return rows

# 1 option 2 Batch inference cho nhi·ªÅu c√¢u
def batch_predict(sentences, threshold):
    rows = []

    for sid, text in enumerate(sentences, 1):
        text = text.strip()
        if not text:
            continue

        preds = predict(text, threshold)

        if len(preds) == 0:
            rows.append({
                "sentence_id": sid,
                "sentence": text,
                "aspect": None,
                "sentiment": None,
                "confidence": None
            })
        else:
            for r in preds:
                rows.append({
                    "sentence_id": sid,
                    "sentence": text,
                    "aspect": r["aspect"],
                    "sentiment": r["sentiment"],
                    "confidence": r["confidence"]
                })

    return rows

# 2 Upload .txt
st.subheader("üìÇ Upload file .txt (m·ªói d√≤ng = 1 c√¢u)")
uploaded_file = st.file_uploader("Ch·ªçn file .txt", type=["txt"])


# # 3 X·ª≠ l√Ω khi upload

if uploaded_file is not None:
    raw_text = uploaded_file.read().decode("utf-8")
    sentences = raw_text.splitlines()

    with st.spinner("üîç ƒêang ph√¢n t√≠ch..."):
        results = batch_predict(sentences, threshold)

    df = pd.DataFrame(results)


    # 4 Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£
    st.subheader("üìã B·∫£ng k·∫øt qu·∫£")

    st.dataframe(
        df.fillna("‚Äî"),
        use_container_width=True
    )
    # # Th·ªëng k√™ aspect & sentiment

        # ===============================
    # BUILD pivot_df 
    # ===============================

    aspect_sentiment_df = (
        df[df["aspect"].notna() & df["sentiment"].notna()]
        .groupby(["aspect", "sentiment"])
        .size()
        .reset_index(name="count")
    )

    pivot_df = aspect_sentiment_df.pivot(
        index="aspect",
        columns="sentiment",
        values="count"
    ).fillna(0)



    # Chuy·ªÉn pivot v·ªÅ d·∫°ng long
    plot_df = (
        pivot_df
        .reset_index()
        .melt(id_vars="aspect", var_name="sentiment", value_name="count")
    )

    # T·∫°o th·ª© t·ª± aspect theo t·ªïng count
    aspect_order = (
        pivot_df.sum(axis=1)
        .sort_values(ascending=False)
        .index
        .tolist()
    )
    chart = (
        alt.Chart(plot_df)
        .mark_bar()
        .encode(
            x=alt.X(
                "aspect:N",
                sort=aspect_order,        # üî• √âP TH·ª® T·ª∞ T·∫†I ƒê√ÇY
                title="Aspect"
            ),
            y=alt.Y(
                "count:Q",
                title="Count"
            ),
            color=alt.Color(
                "sentiment:N",
                scale=alt.Scale(
                    domain=["positive", "neutral", "negative"],
                    range=["#2ecc71", "#f1c40f", "#e74c3c"]
                ),
                title="Sentiment"
            ),
            tooltip=["aspect", "sentiment", "count"]
        )
        .properties(height=400)
    )

    st.altair_chart(chart, use_container_width=True)


    
    # # Th·ªëng k√™ aspect & sentiment
    # aspect_sentiment_df = (
    #     df[df["aspect"].notna() & df["sentiment"].notna()]
    #     .groupby(["aspect", "sentiment"])
    #     .size()
    #     .reset_index(name="count")
    # )

    # pivot_df = aspect_sentiment_df.pivot(
    #     index="aspect",
    #     columns="sentiment",
    #     values="count"
    # ).fillna(0)

    # TOP_K = 10

    # # L·∫•y TOP_K aspect nhi·ªÅu nh·∫•t
    # pivot_df = pivot_df.loc[
    #     pivot_df.sum(axis=1).sort_values(ascending=False).head(TOP_K).index
    # ]

    # # üî• S·∫ÆP X·∫æP L·∫†I THEO TH·ª® T·ª∞ GI·∫¢M D·∫¶N
    # pivot_df = pivot_df.loc[
    #     pivot_df.sum(axis=1).sort_values(ascending=False).index
    # ]

    # st.subheader("üìä Aspect √ó Sentiment distribution")
    # st.bar_chart(pivot_df)

        

    # 5 SUMMARY
    # Th·ªëng k√™ % c√¢u c√≥ aspect
    total_sent = df["sentence_id"].nunique()
    sent_with_aspect = df[df["aspect"].notna()]["sentence_id"].nunique()

    st.metric(
        label="üìå % c√¢u c√≥ aspect",
        value=f"{sent_with_aspect / total_sent * 100:.2f}%"
    )




    # üìä Sentiment distribution
    st.subheader("üìä Sentiment distribution")

    sentiment_counts = (
        df[df["sentiment"].notna()]
        ["sentiment"]
        .value_counts()
    )

    # s·∫Øp x·∫øp theo th·ª© t·ª± mong mu·ªën
    sentiment_order = ["positive", "neutral", "negative"]

    sentiment_counts = sentiment_counts.reindex(sentiment_order).fillna(0)

    st.bar_chart(sentiment_counts)



    # 6 DOWNLOAD CSV & JSON
    st.subheader("‚¨áÔ∏è Download k·∫øt qu·∫£")

    csv_data = df.to_csv(index=False).encode("utf-8")
    json_data = df.to_json(orient="records", force_ascii=False, indent=2).encode("utf-8")

    col1, col2 = st.columns(2)

    with col1:
        st.download_button(
            "‚¨á Download CSV",
            csv_data,
            file_name="absa_results.csv",
            mime="text/csv"
        )

    with col2:
        st.download_button(
            "‚¨á Download JSON",
            json_data,
            file_name="absa_results.json",
            mime="application/json"
        )



## khuy·∫øn ngh·ªã
def compute_aspect_stats(df):
    stats = (
        df[df["aspect"].notna() & df["sentiment"].notna()]
        .groupby(["aspect", "sentiment"])
        .size()
        .unstack(fill_value=0)
    )

    # ƒë·∫£m b·∫£o ƒë·ªß 3 c·ªôt
    for col in ["positive", "negative", "neutral"]:
        if col not in stats.columns:
            stats[col] = 0

    stats["total"] = stats.sum(axis=1)

    stats["positive_ratio"] = stats["positive"] / stats["total"]
    stats["negative_ratio"] = stats["negative"] / stats["total"]
    stats["neutral_ratio"]  = stats["neutral"]  / stats["total"]

    return stats.reset_index()

    
def generate_recommendations(aspect_stats):
    recommendations = []

    for _, row in aspect_stats.iterrows():
        aspect = row["aspect"]
        total = row["total"]

        if total < 5:
            continue  # b·ªè qua aspect qu√° √≠t d·ªØ li·ªáu

        pos = row["positive_ratio"]
        neg = row["negative_ratio"]
        neu = row["neutral_ratio"]

        if neg >= 0.4:
            rec = f"‚ö†Ô∏è **{aspect}** c√≥ t·ª∑ l·ªá ph·∫£n h·ªìi ti√™u c·ª±c cao ({neg:.0%}). N√™n ∆∞u ti√™n c·∫£i thi·ªán."
        elif pos >= 0.6:
            rec = f"‚≠ê **{aspect}** l√† ƒëi·ªÉm m·∫°nh ({pos:.0%} ph·∫£n h·ªìi t√≠ch c·ª±c). N√™n duy tr√¨ v√† qu·∫£ng b√°."
        elif neu >= 0.5:
            rec = f"ü§î **{aspect}** c√≥ nhi·ªÅu ph·∫£n h·ªìi trung t√≠nh. C√≥ th·ªÉ kh√°ch h√†ng ch∆∞a c·∫£m nh·∫≠n r√µ, c·∫ßn c·∫£i thi·ªán tr·∫£i nghi·ªám."
        else:
            rec = f"‚ÑπÔ∏è **{aspect}** c√≥ ph·∫£n h·ªìi t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng."

        recommendations.append(rec)

    return recommendations

if df is not None and len(df) > 0:

    aspect_stats = compute_aspect_stats(df)

    #b·∫£ng ph√¢n t√≠ch

    st.subheader("üìã Aspect sentiment summary")

    sorted_df = aspect_stats.sort_values("total", ascending=False)

    st.dataframe(
        sorted_df[
            [
                "aspect",
                "positive",
                "negative",
                "neutral",
                "total",
                "positive_ratio",
                "negative_ratio",
                "neutral_ratio"
            ]
        ],
        height=500
    )

    # 7 Khuy·∫øn ngh·ªã kinh doanh
        
    st.subheader("üß† Business Recommendations")


    recommendations = generate_recommendations(aspect_stats)

    if len(recommendations) == 0:
        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã.")
    else:
        for r in recommendations:
            st.write(r)


